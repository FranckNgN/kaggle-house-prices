{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CatBoost Model - Kaggle GPU Runner\n",
        "\n",
        "This notebook runs the CatBoost model on Kaggle's GPU infrastructure with complete preprocessing pipeline.\n",
        "\n",
        "## Before Running:\n",
        "1. **Enable GPU**: Go to Settings → Accelerator → Select \"GPU\" (P100 or T4)\n",
        "2. **Add Competition Data**: Click \"Add Input\" → Search for \"house-prices-advanced-regression-techniques\" → Add it\n",
        "3. **Run all cells** in order\n",
        "\n",
        "## What This Notebook Does:\n",
        "- Fixes numpy/scipy compatibility issues\n",
        "- Clones your GitHub repository\n",
        "- Sets up Kaggle environment\n",
        "- Runs complete preprocessing pipeline (stages 1-8)\n",
        "- Trains CatBoost model with GPU acceleration\n",
        "- Generates submission file\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 1: Clone repository and install dependencies\n",
        "# CRITICAL: Fix numpy/scipy FIRST before any imports\n",
        "\n",
        "import subprocess\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# ======================================================================\n",
        "# STEP 1: Fix numpy/scipy compatibility FIRST\n",
        "# ======================================================================\n",
        "print(\"=\" * 70)\n",
        "print(\"FIXING NUMPY/SCIPY COMPATIBILITY\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Uninstall numpy 2.x completely\n",
        "print(\"Uninstalling numpy 2.x...\")\n",
        "subprocess.run([sys.executable, \"-m\", \"pip\", \"uninstall\", \"-y\", \"numpy\"], \n",
        "               capture_output=True, text=True)\n",
        "\n",
        "# Install numpy 1.26.4 explicitly\n",
        "print(\"Installing numpy 1.26.4...\")\n",
        "result = subprocess.run(\n",
        "    [sys.executable, \"-m\", \"pip\", \"install\", \"--no-cache-dir\", \"numpy==1.26.4\"],\n",
        "    capture_output=True,\n",
        "    text=True\n",
        ")\n",
        "\n",
        "# Install scipy 1.16.3\n",
        "print(\"Installing scipy 1.16.3...\")\n",
        "subprocess.run(\n",
        "    [sys.executable, \"-m\", \"pip\", \"install\", \"--no-cache-dir\", \"scipy==1.16.3\"],\n",
        "    capture_output=True,\n",
        "    text=True\n",
        ")\n",
        "\n",
        "# Verify versions\n",
        "import numpy as np\n",
        "import scipy\n",
        "print(f\"\\n✓ Numpy: {np.__version__}\")\n",
        "print(f\"✓ Scipy: {scipy.__version__}\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# ======================================================================\n",
        "# STEP 2: Clone repository\n",
        "# ======================================================================\n",
        "REPO_URL = \"https://github.com/FranckNgN/kaggle-house-prices.git\"\n",
        "PROJECT_DIR = \"/kaggle/working/project\"\n",
        "\n",
        "# Ensure we're in a valid directory first\n",
        "os.chdir(\"/kaggle/working\")\n",
        "print(f\"\\nCurrent directory: {os.getcwd()}\")\n",
        "\n",
        "# Remove existing directory if it exists (for re-runs)\n",
        "if os.path.exists(PROJECT_DIR):\n",
        "    import shutil\n",
        "    shutil.rmtree(PROJECT_DIR)\n",
        "    print(f\"[INFO] Removed existing project directory\")\n",
        "\n",
        "# Clone repository\n",
        "print(f\"\\nCloning repository from {REPO_URL}...\")\n",
        "result = subprocess.run(\n",
        "    [\"git\", \"clone\", REPO_URL, PROJECT_DIR],\n",
        "    cwd=\"/kaggle/working\",\n",
        "    capture_output=True,\n",
        "    text=True\n",
        ")\n",
        "\n",
        "if result.returncode != 0:\n",
        "    print(f\"ERROR: Failed to clone repository\")\n",
        "    print(f\"stdout: {result.stdout}\")\n",
        "    print(f\"stderr: {result.stderr}\")\n",
        "    raise RuntimeError(\"Repository clone failed\")\n",
        "\n",
        "print(f\"[OK] Repository cloned to {PROJECT_DIR}\")\n",
        "\n",
        "# Change to project directory\n",
        "os.chdir(PROJECT_DIR)\n",
        "print(f\"Current directory: {os.getcwd()}\")\n",
        "\n",
        "# ======================================================================\n",
        "# STEP 3: Install dependencies (skip numpy/scipy since we already fixed them)\n",
        "# ======================================================================\n",
        "print(\"\\nInstalling dependencies (excluding numpy/scipy)...\")\n",
        "# Install without dependencies first to avoid reinstalling numpy/scipy\n",
        "result = subprocess.run(\n",
        "    [sys.executable, \"-m\", \"pip\", \"install\", \"-r\", \"requirements.txt\", \"--no-deps\"],\n",
        "    capture_output=True,\n",
        "    text=True\n",
        ")\n",
        "\n",
        "# Install core dependencies individually\n",
        "print(\"Installing core ML libraries...\")\n",
        "core_deps = [\"pandas==2.3.3\", \"scikit-learn==1.7.2\", \"optuna>=3.0.0\",\n",
        "             \"xgboost>=2.0.0\", \"lightgbm>=4.0.0\", \"catboost>=1.2.0\"]\n",
        "for dep in core_deps:\n",
        "    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", dep], \n",
        "                   capture_output=True, text=True)\n",
        "\n",
        "print(\"[OK] Dependencies installed\")\n",
        "\n",
        "# Add project to Python path\n",
        "sys.path.insert(0, PROJECT_DIR)\n",
        "print(f\"\\n[OK] Project root added to Python path\")\n",
        "print(\"=\" * 70)\n",
        "print(\"[SUCCESS] Cell 1 complete - ready for Cell 2!\")\n",
        "print(\"=\" * 70)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 2: Setup Kaggle environment (symlinks, GPU verification)\n",
        "from kaggle.remote.setup_kaggle import setup_kaggle_environment\n",
        "\n",
        "setup_kaggle_environment()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 4: Run preprocessing pipeline (stages 1-8)\n",
        "# This generates train_process8.csv and test_process8.csv required for model training\n",
        "\n",
        "import subprocess\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "PROJECT_DIR = \"/kaggle/working/project\"\n",
        "os.chdir(PROJECT_DIR)\n",
        "sys.path.insert(0, PROJECT_DIR)\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"RUNNING PREPROCESSING PIPELINE\")\n",
        "print(\"=\" * 70)\n",
        "print(\"This will run all 8 preprocessing stages:\")\n",
        "print(\"  1. Cleaning\")\n",
        "print(\"  2. Data Engineering\")\n",
        "print(\"  3. Skew/Kurtosis\")\n",
        "print(\"  4. Feature Engineering\")\n",
        "print(\"  5. Scaling\")\n",
        "print(\"  6. Categorical Encoding\")\n",
        "print(\"  7. Feature Selection\")\n",
        "print(\"  8. Target Encoding\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Run preprocessing\n",
        "print(\"\\nStarting preprocessing pipeline...\")\n",
        "result = subprocess.run(\n",
        "    [sys.executable, \"notebooks/preprocessing/run_preprocessing.py\"],\n",
        "    cwd=PROJECT_DIR,\n",
        "    capture_output=True,\n",
        "    text=True\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "if result.returncode == 0:\n",
        "    print(\"[OK] Preprocessing completed successfully!\")\n",
        "    # Show last part of output\n",
        "    if result.stdout:\n",
        "        lines = result.stdout.split('\\n')\n",
        "        print(\"\\nLast 20 lines of output:\")\n",
        "        for line in lines[-20:]:\n",
        "            if line.strip():\n",
        "                print(f\"  {line}\")\n",
        "else:\n",
        "    print(\"[WARNING] Preprocessing had errors (check output above)\")\n",
        "    if result.stderr:\n",
        "        print(\"\\nError output (last 500 chars):\")\n",
        "        print(result.stderr[-500:])\n",
        "\n",
        "# Verify required files exist\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"VERIFYING PREPROCESSED FILES\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "train_file = Path(PROJECT_DIR) / \"data\" / \"interim\" / \"train\" / \"train_process8.csv\"\n",
        "test_file = Path(PROJECT_DIR) / \"data\" / \"interim\" / \"test\" / \"test_process8.csv\"\n",
        "\n",
        "train_exists = train_file.exists()\n",
        "test_exists = test_file.exists()\n",
        "\n",
        "print(f\"Train file: {train_file.name}\")\n",
        "print(f\"  Exists: {'✓ YES' if train_exists else '✗ NO'}\")\n",
        "if train_exists:\n",
        "    size = train_file.stat().st_size / 1024\n",
        "    print(f\"  Size: {size:.1f} KB\")\n",
        "\n",
        "print(f\"\\nTest file: {test_file.name}\")\n",
        "print(f\"  Exists: {'✓ YES' if test_exists else '✗ NO'}\")\n",
        "if test_exists:\n",
        "    size = test_file.stat().st_size / 1024\n",
        "    print(f\"  Size: {size:.1f} KB\")\n",
        "\n",
        "if train_exists and test_exists:\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"[SUCCESS] Preprocessing complete - ready for model training!\")\n",
        "    print(\"=\" * 70)\n",
        "else:\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"[ERROR] Required files missing!\")\n",
        "    print(\"=\" * 70)\n",
        "    print(\"\\nPlease check the preprocessing output above for errors.\")\n",
        "    raise FileNotFoundError(\"Preprocessed files not found\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 3: Verify GPU availability\n",
        "print(\"Checking GPU with nvidia-smi...\")\n",
        "print(\"-\" * 70)\n",
        "!nvidia-smi\n",
        "\n",
        "print(\"\\n\" + \"-\" * 70)\n",
        "from kaggle.remote.gpu_runner import verify_gpu_setup, print_gpu_usage_info\n",
        "\n",
        "gpu_available = verify_gpu_setup()\n",
        "print()\n",
        "print_gpu_usage_info()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 4: Run CatBoost model training (GPU-accelerated)\n",
        "# This will:\n",
        "# - Load preprocessed data\n",
        "# - Run Optuna hyperparameter optimization\n",
        "# - Train final model with best parameters\n",
        "# - Generate submission file\n",
        "\n",
        "%run notebooks/Models/9catBoostModel.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 5: Verify outputs and check results\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"TRAINING RESULTS SUMMARY\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Check submission files\n",
        "submissions_dir = Path(\"/kaggle/working/project/data/submissions\")\n",
        "print(\"\\nSubmission files:\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "if submissions_dir.exists():\n",
        "    submission_files = list(submissions_dir.rglob(\"*.csv\"))\n",
        "    for file in sorted(submission_files):\n",
        "        if file.name != \"sample_submission.csv\":\n",
        "            size_kb = file.stat().st_size / 1024\n",
        "            print(f\"  {file.name}: {size_kb:.1f} KB\")\n",
        "            # Show first few rows\n",
        "            df = pd.read_csv(file)\n",
        "            print(f\"    Shape: {df.shape}\")\n",
        "            print(f\"    First predictions: {df.head(3).to_string()}\")\n",
        "else:\n",
        "    print(\"  No submissions directory found\")\n",
        "\n",
        "# Check model performance log\n",
        "runs_dir = Path(\"/kaggle/working/project/runs\")\n",
        "perf_file = runs_dir / \"model_performance.csv\"\n",
        "print(\"\\nModel Performance:\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "if perf_file.exists():\n",
        "    df = pd.read_csv(perf_file)\n",
        "    print(f\"Total model runs: {len(df)}\")\n",
        "    if len(df) > 0:\n",
        "        latest = df.iloc[-1]\n",
        "        print(f\"\\nLatest Run:\")\n",
        "        print(f\"  Model: {latest['model']}\")\n",
        "        print(f\"  CV RMSE: {latest['rmse']:.6f}\")\n",
        "        print(f\"  Runtime: {latest.get('runtime', 'N/A')}\")\n",
        "        print(f\"\\nFull performance log:\")\n",
        "        print(df.to_string())\n",
        "else:\n",
        "    print(\"  No performance log found\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"[INFO] To download submission file:\")\n",
        "print(\"  1. Go to Kaggle notebook 'Data' output panel (right side)\")\n",
        "print(\"  2. Navigate to /kaggle/working/project/data/submissions/\")\n",
        "print(\"  3. Download the latest submission CSV file\")\n",
        "print(\"=\" * 70)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
